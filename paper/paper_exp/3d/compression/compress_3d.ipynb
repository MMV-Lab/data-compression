{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import modules:\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import monai\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    Compose,\n",
    "    AddChannel,\n",
    "    Transform,\n",
    "    Transpose,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from compressai.zoo import image_models, models\n",
    "from compressai.zoo.pretrained import load_pretrained\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "from tqdm.contrib import tenumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "# which cell line to download: in the paper, we tested on four nuclear structures:\n",
    "# - fibrillarin (cline = \"FBL\")\n",
    "# - nucleophosmin (cline = \"NPM1\")\n",
    "# - lamin b1 (cline = \"LMNB1\")\n",
    "# - histon H2B (cline = \"HIST1H2BJ\")\n",
    "cline = \"FBL\"\n",
    "\n",
    "# set up path 3D\n",
    "parent_path_3d = Path(\"../../../../data/labelfree3D\") / f\"{cline}\"\n",
    "train_path_3d = parent_path_3d / Path(\"train\")\n",
    "holdout_path_3d = parent_path_3d / Path(\"holdout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# define funcs and hyper-parameters:\n",
    "\n",
    "_SEED = 2023\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(_SEED)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def normalizeItensity(image):\n",
    "    # Convert the image data to a floating-point data type\n",
    "    img = image.astype(np.float32)\n",
    "    # Convert the image to a toch Tensor\n",
    "    img = torch.from_numpy(img)\n",
    "    # Normalize the intensity of the image using the MONAI NormalizeIntensity transform\n",
    "    normalize_intensity = monai.transforms.NormalizeIntensity()\n",
    "    img_normalized = normalize_intensity(img)\n",
    "    # Convert the normalized image back to a numpy array\n",
    "    return img_normalized.numpy()\n",
    "\n",
    "\n",
    "def transform_img(image):\n",
    "    img = image.astype(np.float32) / 65535\n",
    "    return img\n",
    "\n",
    "\n",
    "def compare_images(path1, path2, gt=True):\n",
    "    # Load the two images\n",
    "    image1 = AICSImage(path1).get_image_data(\"ZYX\")\n",
    "    image2 = AICSImage(path2).get_image_data(\"ZYX\")\n",
    "    # scale to 0-1\n",
    "    scaler = ScaleIntensity()\n",
    "    image1 = scaler(image1).cpu().numpy()\n",
    "    image2 = scaler(image2).cpu().numpy()\n",
    "    mse_value = mse(image1, image2)\n",
    "    ssim_value = ssim(image1, image2, data_range=1)\n",
    "    psnr_value = psnr(image1, image2, data_range=1)\n",
    "    corr = np.corrcoef(image1.ravel(), image2.ravel())[0, 1]\n",
    "    # psnr = 10 * np.log10(1 / (mse + 0.000001))\n",
    "    return mse, ssim_value, psnr_value, corr\n",
    "\n",
    "\n",
    "class Normalize(Transform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Rescale unint16 values to [0,1]\n",
    "        result = img / 65535.0\n",
    "        return result\n",
    "\n",
    "\n",
    "def torch2img(x: torch.Tensor):\n",
    "    # Convert  tensor to numpy array and rescale to uint16\n",
    "    np_array = x.clamp_(0, 1).squeeze().cpu().detach().numpy()\n",
    "    return np_array\n",
    "    # return (np_array * (2**16 - 1)).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have the pre-trained model in 3D cases, we need to train from scratch. Here we use `bmshj2018-factorized_3d` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pretrain on mse loss for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../../../train.py -d {parent_path_3d} \\\n",
    "                    --train_split train \\\n",
    "                    --test_split holdout \\\n",
    "                    --aux-learning-rate 1e-3 \\\n",
    "                    --lambda 0.18 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 1e-4 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --model bmshj2018-factorized_3d \\\n",
    "                    --use_3D \\\n",
    "                    --quality 8 \\\n",
    "                    --metric mse \\\n",
    "                    --cuda \\\n",
    "                    --save_path ./pretrain.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fine-tune with another 50 epochs using ms-ssim loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 ../train.py -d {parent_path_3d} \\\n",
    "                    --train_split train \\\n",
    "                    --test_split holdout \\\n",
    "                    --aux-learning-rate 1e-4 \\\n",
    "                    --lambda 220.0 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 5e-5 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --use_3D \\\n",
    "                    --model bmshj2018-factorized_3d \\\n",
    "                    --checkpoint ./pretrain.pth.tar \\\n",
    "                    --quality 8 \\\n",
    "                    --metric ms-ssim \\\n",
    "                    --cuda \\\n",
    "                    --save_path ./fine-tune.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of using `codec.py`, we try to directly forward the network to get the prediction. We will use sliding window inference to avoid memory overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model = \"bmshj2018-factorized_3d\"\n",
    "device = torch.device(\"cpu\")\n",
    "metric = \"ms-ssim\"\n",
    "quality = 8\n",
    "model_info = models[model]\n",
    "checkpoint = \"./fine-tune.pth.tar\"\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        Transpose(indices=(0, 3, 2, 1)),\n",
    "        Normalize(),\n",
    "    ]\n",
    ")\n",
    "state_dict = torch.load(checkpoint, map_location=device)[\"state_dict\"]\n",
    "state_dict = load_pretrained(state_dict)\n",
    "net = (\n",
    "    model_info(quality=quality, metric=metric, pretrained=False)\n",
    "    .from_state_dict(state_dict)\n",
    "    .to(device)\n",
    "    .eval()\n",
    ")\n",
    "net.update(force=True)\n",
    "\n",
    "# Global variable to store the call count\n",
    "call_count = 0\n",
    "\n",
    "\n",
    "# Custom decorator for counting function calls\n",
    "def counter(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        global call_count  # Access the global variable\n",
    "        call_count += 1  # Increment the call count\n",
    "        result = func(*args, **kwargs)\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@counter\n",
    "def infer(img):\n",
    "    \"\"\"\n",
    "    img: (tensor) N x C x Z x H x W\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        out = net(img)[\"x_hat\"]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = sorted(holdout_path_3d.glob(\"*IM.tiff\"))\n",
    "output_dir = holdout_path_3d / \"bmshj2018-factorized_3d_ms-ssim_8\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "compress_dir = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [1:14:06<00:00, 42.35s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, input in tenumerate(input_dir):\n",
    "    img = transform(input)[0].unsqueeze(0).unsqueeze(0).to(device)\n",
    "    # [img]->img, add batch channel, to device.\n",
    "    pred = sliding_window_inference(\n",
    "        inputs=img,\n",
    "        predictor=infer,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        roi_size=[32, 256, 256],\n",
    "        sw_batch_size=4,\n",
    "        overlap=0.1,\n",
    "        mode=\"gaussian\",\n",
    "    )\n",
    "    pred = torch2img(pred)\n",
    "    OmeTiffWriter.save(\n",
    "        pred,\n",
    "        (output_dir / f\"{input.stem}_decoded{input.suffix}\"),\n",
    "        dim_order=\"ZYX\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [07:22,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.33440911084474484 SSIM: 0.9220190446920535 PSNR: 28.136645543964296 CORR: 0.9483616418217692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_paths = sorted((compress_dir).glob(\"*.tiff\"))\n",
    "mse_value = AverageMeter()\n",
    "ssim_value = AverageMeter()\n",
    "psnr_value = AverageMeter()\n",
    "corr_value = AverageMeter()\n",
    "for i, (decode_path, raw_path) in tenumerate(zip(decoded_paths, input_dir)):\n",
    "    tmp_mse, tmp_ssim, tmp_psnr, tmp_corr = compare_images(decode_path, raw_path)\n",
    "    mse_value.update(tmp_mse)\n",
    "    ssim_value.update(tmp_ssim)\n",
    "    psnr_value.update(tmp_psnr)\n",
    "    corr_value.update(tmp_corr)\n",
    "print(\n",
    "    \"MSE:\",\n",
    "    mse_value.avg,\n",
    "    \"SSIM:\",\n",
    "    ssim_value.avg,\n",
    "    \"PSNR:\",\n",
    "    psnr_value.avg,\n",
    "    \"CORR:\",\n",
    "    corr_value.avg,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_compressAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
