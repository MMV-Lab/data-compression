{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3d adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import quilt3\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 2023\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off pandas parser warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# tunr off ome_types parser warning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cline = \"FBL\"\n",
    "num_samples_per_cell_line = 10 # choose what you need, with roughly 80/20 training/validation split \n",
    "# set up path\n",
    "parent_path = Path(\"/mnt/eternus/users/Yu/project/data_compression/data/labelfree_3d\")\n",
    "parent_path.mkdir(exist_ok=True)\n",
    "raw_path = parent_path / Path(\"download\")\n",
    "raw_path.mkdir(exist_ok=True)\n",
    "train_path = parent_path / Path(\"train\")\n",
    "train_path.mkdir(exist_ok=True)\n",
    "holdout_path = parent_path / Path(\"holdout\")\n",
    "holdout_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading manifest: 100%|██████████| 484465/484465 [00:14<00:00, 34.4k/s]\n",
      "100%|██████████| 1.69G/1.69G [00:40<00:00, 41.8MB/s] \n",
      "Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# connect to quilt and load meta table\n",
    "pkg = quilt3.Package.browse(\n",
    "    \"aics/hipsc_single_cell_image_dataset\", registry=\"s3://allencell\"\n",
    ")\n",
    "meta_df_obj = pkg[\"metadata.csv\"]\n",
    "meta_df_obj.fetch(parent_path / \"meta.csv\")\n",
    "meta_df = pd.read_csv(parent_path / \"meta.csv\")\n",
    "# fetch the data of the specific cell line\n",
    "meta_df_line = meta_df.query(\"structure_name==@cline\")\n",
    "# collapse the data table based on FOVId\n",
    "meta_df_line.drop_duplicates(subset=\"FOVId\", inplace=True)\n",
    "# reset index\n",
    "meta_df_line.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the images and re-slice into input (BF) and ground truth (fluorescent) images\n",
    "for row in meta_df_line.itertuples():\n",
    "    if row.Index >= num_samples_per_cell_line:\n",
    "        break\n",
    "    \n",
    "    # fetch the raw image (multi-channel)\n",
    "    subdir_name = row.fov_path.split(\"/\")[0]\n",
    "    file_name = row.fov_path.split(\"/\")[1]\n",
    "\n",
    "    local_fn = raw_path / f\"{row.FOVId}_original.tiff\"\n",
    "    pkg[subdir_name][file_name].fetch(local_fn)\n",
    "\n",
    "    # extract the bf and structures channel\n",
    "    reader = AICSImage(local_fn)\n",
    "    bf_img = reader.get_image_data(\n",
    "        \"ZYX\", C=row.ChannelNumberBrightfield, S=0, T=0\n",
    "    )\n",
    "    str_img = reader.get_image_data(\n",
    "        \"ZYX\", C=row.ChannelNumberStruct, S=0, T=0\n",
    "    )\n",
    "    if random.random() < 0.2:\n",
    "        data_path = holdout_path\n",
    "    else:\n",
    "        data_path = train_path\n",
    "        \n",
    "    im_fn = data_path / f\"{row.FOVId}_IM.tiff\"\n",
    "    gt_fn = data_path / f\"{row.FOVId}_GT.tiff\"\n",
    "    OmeTiffWriter.save(bf_img, im_fn, dim_order=\"ZYX\")\n",
    "    OmeTiffWriter.save(str_img, gt_fn, dim_order=\"ZYX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may remove the download folder now.\n",
    "from shutil import rmtree\n",
    "import os\n",
    "rmtree(raw_path)\n",
    "os.remove(parent_path / \"meta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../train.py -d /mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/experiment/3d_adaptation/data \\\n",
    "                    --train_split train \\\n",
    "                    --test_split test \\\n",
    "                    --aux-learning-rate 1e-3 \\\n",
    "                    --lambda 0.18 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 1e-4 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --model bmshj2018-factorized_3d \\\n",
    "                    --use_3D \\\n",
    "                    --quality 8 \\\n",
    "                    --metric {metric} \\\n",
    "                    --cuda \\\n",
    "                    --save_path /mnt/eternus/users/Yu/project/data_compression/experiment/3d_adaptation/model/fine_tune_v13.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with 2D:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 3D priminary result is not good, we again come back to 2d to see the intermidiate result. The objective is to jusitify the correctness of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../train.py -d /mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/data/labelfree_2d \\\n",
    "                    --train_split train \\\n",
    "                    --test_split test \\\n",
    "                    --aux-learning-rate 1e-3 \\\n",
    "                    --lambda 0.18 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 1e-4 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --model bmshj2018-factorized \\\n",
    "                    --quality 8 \\\n",
    "                    --metric {metric} \\\n",
    "                    --cuda \\\n",
    "                    --save_path /mnt/eternus/users/Yu/project/data_compression/experiment/3d_adaptation/model/fine_tune_v15.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D fine-tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like the bad 3d result is due to the lack of enough data, so we add more data to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"/mnt/eternus/users/Jianxu/projects/im2im_experiments_v1/data/labelfree3D/FBL/\"\n",
    "metric = \"mse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../train.py -d {training_path} \\\n",
    "                    --train_split train \\\n",
    "                    --test_split holdout \\\n",
    "                    --aux-learning-rate 1e-3 \\\n",
    "                    --lambda 0.18 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 1e-4 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --use_3D \\\n",
    "                    --model bmshj2018-factorized_3d \\\n",
    "                    --quality 8 \\\n",
    "                    --metric {metric} \\\n",
    "                    --cuda \\\n",
    "                    --save_path /mnt/eternus/users/Yu/project/data_compression/experiment/3d_adaptation/model/3d_adaptation_v1.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we get a reasonable pretrained model to start. The next thing is to use ms-ssim loss to fine tune it. Below is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 ../train.py -d /mnt/eternus/users/Jianxu/projects/im2im_experiments_v1/data/labelfree3D/FBL/ \\\n",
    "                    --train_split train \\\n",
    "                    --test_split holdout \\\n",
    "                    --aux-learning-rate 1e-4 \\\n",
    "                    --lambda 220.0 \\\n",
    "                    --epochs 50 \\\n",
    "                    -lr 5e-5 \\\n",
    "                    --batch-size 2 \\\n",
    "                    --use_3D \\\n",
    "                    --model bmshj2018-factorized_3d \\\n",
    "                    --checkpoint /mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/experiment/3d_adaptation/model/3d_adaptation_v1_best.pth.tar \\\n",
    "                    --quality 8 \\\n",
    "                    --metric ms-ssim \\\n",
    "                    --cuda \\\n",
    "                    --save_path /mnt/eternus/users/Yu/project/data_compression/experiment/3d_adaptation/model/3d_adaptation_v2.pth.tar \\\n",
    "                    --seed 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of using `codec.py`, we try to directly forward the network to get the prediction. We will use sliding window inference to avoid memory overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    RandSpatialCropSamples,\n",
    "    LoadImage,\n",
    "    SaveImage,\n",
    "    Compose,\n",
    "    AddChannel,\n",
    "    RepeatChannel,\n",
    "    ToTensor,\n",
    "    Transform,\n",
    "    Transpose,\n",
    "    CastToType,\n",
    "    EnsureType,\n",
    "    ScaleIntensityRangePercentiles,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from compressai.zoo import image_models, models\n",
    "from compressai.zoo.pretrained import load_pretrained\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import  OmeTiffWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(Transform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Rescale unint16 values to [0,1]\n",
    "        result = img / 65535.0\n",
    "        return result\n",
    "    \n",
    "def torch2img(x: torch.Tensor): \n",
    "    # Convert  tensor to numpy array and rescale to uint16\n",
    "    np_array = x.clamp_(0, 1).squeeze().cpu().detach().numpy()\n",
    "    return np_array\n",
    "    # return (np_array * (2**16 - 1)).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n"
     ]
    }
   ],
   "source": [
    "model = \"bmshj2018-factorized_3d\"\n",
    "device = torch.device('cpu')\n",
    "metric = \"ms-ssim\"\n",
    "quality = 8\n",
    "model_info = models[model]\n",
    "checkpoint = \"/mnt/eternus/users/Yu/project/data_compression/experiment/3d_adaptation/model/3d_adaptation_v2_best.pth.tar\"\n",
    "# transform = Compose([LoadImage(image_only=True),AddChannel(), Transpose(indices = (0,3,1,2)), Normalize(), RandSpatialCropSamples(roi_size = (64,256,256), num_samples = 1, random_size = False, random_center = False)])\n",
    "transform = Compose([LoadImage(image_only=True),AddChannel(), Transpose(indices = (0,3,2,1)), Normalize()])\n",
    "state_dict = torch.load(checkpoint, map_location = device)['state_dict']\n",
    "state_dict = load_pretrained(state_dict)\n",
    "net = model_info(quality=quality, metric=metric, pretrained=False).from_state_dict(state_dict).to(device).eval()\n",
    "\n",
    "def infer(img):\n",
    "    \"\"\"\n",
    "    img: (tensor) N x C x Z x H x W\n",
    "    \"\"\"\n",
    "    out = net(img)[\"x_hat\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"/mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/experiment/3d_adaptation/data/test/7632_IM.tiff\"\n",
    "output_dir = \"/mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/experiment/3d_adaptation/data/pred/7632_test.tiff\"\n",
    "img = transform(input)[0].unsqueeze(0).unsqueeze(0).to(device) #[img]->img, add batch channel, to device.\n",
    "pred = sliding_window_inference(inputs=img,\n",
    "                                predictor=infer,\n",
    "                                device=torch.device(\"cpu\"),\n",
    "                                roi_size = [32, 256, 256],\n",
    "                                sw_batch_size = 4,\n",
    "                                overlap = 0.1,\n",
    "                                mode = 'gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save the img:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n"
     ]
    }
   ],
   "source": [
    "img = torch2img(img)\n",
    "pred = torch2img(pred)\n",
    "OmeTiffWriter.save(img, output_dir, dim_order=\"ZYX\")\n",
    "OmeTiffWriter.save(pred, output_dir.replace('test','pred'), dim_order=\"ZYX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test using mse, ssim, psnr and pearson corr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_image(img, pred, dimension = '3d'):\n",
    "    \"\"\"\n",
    "    Calculate metrics: mse, ssim, psnr, corr\n",
    "    \"\"\"\n",
    "    assert img.shape == pred.shape, \"shape should be the same!\"\n",
    "    if dimension.lower() == '3d':\n",
    "        num_pixel = img.shape[-1] * img.shape[-2] * img.shape[-3]\n",
    "    elif dimension.lower() == '2d':\n",
    "        num_pixel = img.shape[-1] * img.shape[-2]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimension input. Expected '2d' or '3d'.\")\n",
    "    mse = np.sum((img - pred) ** 2)/(num_pixel)\n",
    "    ssim_value = ssim(img, pred, data_range = 1)\n",
    "    psnr_value = psnr(img, pred, data_range = 1)\n",
    "    corr = np.corrcoef(img.ravel(), pred.ravel())[0, 1]\n",
    "    return mse, ssim_value, psnr_value, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "- MSE  : 0.0003\n",
      "- SSIM : 0.8894\n",
      "- PSNR : 35.6661\n",
      "- CORR : 0.9240\n"
     ]
    }
   ],
   "source": [
    "mse, ssim_value, psnr_value, corr = compare_image(img, pred)\n",
    "print(f\"\"\"Metrics:\n",
    "- MSE  : {mse:.4f}\n",
    "- SSIM : {ssim_value:.4f}\n",
    "- PSNR : {psnr_value:.4f}\n",
    "- CORR : {corr:.4f}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_compressAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
