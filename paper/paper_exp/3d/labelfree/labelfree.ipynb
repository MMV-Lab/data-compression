{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelfree 3D\n",
    "As the downstream tasks for the image compression. From the brightfield image to the fluorescent image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import modules:\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import monai\n",
    "import torch\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from monai.transforms import (\n",
    "    RandSpatialCropSamples,\n",
    "    LoadImage,\n",
    "    SaveImage,\n",
    "    Compose,\n",
    "    AddChannel,\n",
    "    RepeatChannel,\n",
    "    ToTensor,\n",
    "    Transform,\n",
    "    Transpose,\n",
    "    CastToType,\n",
    "    EnsureType,\n",
    "    ScaleIntensityRangePercentiles,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from tqdm.contrib import tenumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define funcs and hyper-parameters:\n",
    "\n",
    "_SEED = 2023\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(_SEED)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def normalizeItensity(image):\n",
    "    # Convert the image data to a floating-point data type\n",
    "    img = image.astype(np.float32)\n",
    "    # Convert the image to a toch Tensor\n",
    "    img = torch.from_numpy(img)\n",
    "    # Normalize the intensity of the image using the MONAI NormalizeIntensity transform\n",
    "    normalize_intensity = monai.transforms.NormalizeIntensity()\n",
    "    img_normalized = normalize_intensity(img)\n",
    "    # Convert the normalized image back to a numpy array\n",
    "    return img_normalized.numpy()\n",
    "\n",
    "\n",
    "def transform_img(image):\n",
    "    img = image.astype(np.float32) / 65535\n",
    "    return img\n",
    "\n",
    "\n",
    "def compare_image(path1, path2, if_3d=True):\n",
    "    # Load the two images\n",
    "    if if_3d:\n",
    "        image1 = AICSImage(path1).get_image_data(\"ZYX\")\n",
    "        image2 = AICSImage(path2).get_image_data(\"ZYX\")\n",
    "    else:\n",
    "        image1 = AICSImage(path1).get_image_data(\"YX\")\n",
    "        image2 = AICSImage(path2).get_image_data(\"YX\")\n",
    "    # scale to 0-1\n",
    "    scaler = ScaleIntensity()\n",
    "    image1 = scaler(image1).cpu().numpy()\n",
    "    image2 = scaler(image2).cpu().numpy()\n",
    "    if if_3d:\n",
    "        mse = np.sum((image1 - image2) ** 2) / (\n",
    "            image1.shape[-1] * image1.shape[-2] * image1.shape[-3]\n",
    "        )\n",
    "    else:\n",
    "        mse = np.sum((image1 - image2) ** 2) / (image1.shape[-1] * image1.shape[-2])\n",
    "\n",
    "    ssim_value = ssim(image1, image2, data_range=1)\n",
    "    psnr_value = psnr(image1, image2, data_range=1)\n",
    "    corr = np.corrcoef(image1.ravel(), image2.ravel())[0, 1]\n",
    "    # psnr = 10 * np.log10(1 / (mse + 0.000001))\n",
    "    return mse, ssim_value, psnr_value, corr\n",
    "\n",
    "\n",
    "def calculate_metric(fn_list1, fn_list2):\n",
    "    mse_value = AverageMeter()\n",
    "    ssim_value = AverageMeter()\n",
    "    psnr_value = AverageMeter()\n",
    "    corr_value = AverageMeter()\n",
    "    assert len(fn_list1) == len(\n",
    "        fn_list2\n",
    "    ), f\"should have the same length, but have {len(fn_list1)} and {len(fn_list2)}\"\n",
    "\n",
    "    for i, (fn1, fn2) in tenumerate(zip(sorted(fn_list1), sorted(fn_list2))):\n",
    "        tmp_mse, tmp_ssim, tmp_psnr, tmp_corr = compare_image(fn1, fn2)\n",
    "        mse_value.update(tmp_mse)\n",
    "        ssim_value.update(tmp_ssim)\n",
    "        psnr_value.update(tmp_psnr)\n",
    "        corr_value.update(tmp_corr)\n",
    "    print(\n",
    "        \"MSE:\",\n",
    "        mse_value.avg,\n",
    "        \"SSIM:\",\n",
    "        ssim_value.avg,\n",
    "        \"PSNR:\",\n",
    "        psnr_value.avg,\n",
    "        \"CORR:\",\n",
    "        corr_value.avg,\n",
    "    )\n",
    "\n",
    "\n",
    "class Normalize(Transform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Rescale unint16 values to [0,1]\n",
    "        result = img / 65535.0\n",
    "        return result\n",
    "\n",
    "\n",
    "def torch2img(x: torch.Tensor):\n",
    "    # Convert  tensor to numpy array and rescale to uint16\n",
    "    np_array = x.clamp_(0, 1).squeeze().cpu().detach().numpy()\n",
    "    return np_array\n",
    "    # return (np_array * (2**16 - 1)).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# run the run_im2im inference code for uncompressed data.\n",
    "!run_im2im --config_path /mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/uncompressed_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the run_im2im inference code for compressed data.\n",
    "!run_im2im --config_path /mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/compressed_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- gt and compressed\n",
    "- gt and uncompressed\n",
    "- compressed and uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0010345262097846528 SSIM: 0.8494615339342872 PSNR: 30.060456945449076 CORR: 0.5981160373078679\n"
     ]
    }
   ],
   "source": [
    "# gt and compressed:\n",
    "compress_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/prediction/compressed\"\n",
    "    ).glob(\"*.tiff\")\n",
    ")\n",
    "gt_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Jianxu/projects/im2im_experiments_v1/data/labelfree3D/FBL/holdout\"\n",
    "    ).glob(\"*GT.tiff\")\n",
    ")\n",
    "calculate_metric(compress_dir, gt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0005973280223174922 SSIM: 0.9268127516433369 PSNR: 32.60571312426753 CORR: 0.906572002216079\n"
     ]
    }
   ],
   "source": [
    "# gt and uncompressed:\n",
    "uncompress_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/prediction/uncompressed\"\n",
    "    ).glob(\"*.tiff\")\n",
    ")\n",
    "gt_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Jianxu/projects/im2im_experiments_v1/data/labelfree3D/FBL/holdout\"\n",
    "    ).glob(\"*GT.tiff\")\n",
    ")\n",
    "calculate_metric(uncompress_dir, gt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [07:41,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0014884366131589371 SSIM: 0.8203372214022198 PSNR: 28.542511661908915 CORR: 0.6576589413189577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compressed and uncompressed:\n",
    "compress_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/prediction/compressed\"\n",
    "    ).glob(\"*.tiff\")\n",
    ")\n",
    "uncompress_dir = sorted(\n",
    "    Path(\n",
    "        \"/mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/3d/labelfree/prediction/uncompressed\"\n",
    "    ).glob(\"*.tiff\")\n",
    ")\n",
    "calculate_metric(compress_dir, uncompress_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_compressAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
