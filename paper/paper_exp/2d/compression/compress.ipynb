{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is responsible for compressing the data using both classical and deep-learning based methods. Please download the dataset by executing `download_data.ipynb` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import quilt3\n",
    "from pathlib import Path\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "from utils import compression_ratio_space_savings, plot_data, write_metrics\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "!export CUDA_VISIBLE_DEVICES=3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "# which cell line to download: in the paper, we tested on four nuclear structures:\n",
    "# - fibrillarin (cline = \"FBL\")\n",
    "# - nucleophosmin (cline = \"NPM1\")\n",
    "# - lamin b1 (cline = \"LMNB1\")\n",
    "# - histon H2B (cline = \"HIST1H2BJ\")\n",
    "cline = \"FBL\"\n",
    "\n",
    "# set up path 3D\n",
    "parent_path_3d = Path(\"../../../../data/labelfree3D\") / f\"{cline}\"\n",
    "train_path_3d = parent_path_3d / Path(\"train\")\n",
    "holdout_path_3d = parent_path_3d / Path(\"holdout\")\n",
    "\n",
    "# set up path 2D\n",
    "parent_path_2d = Path(\"../../../../data/labelfree2D\") / f\"{cline}\"\n",
    "train_path_2d = parent_path_2d / Path(\"train\")\n",
    "holdout_path_2d = parent_path_2d / Path(\"holdout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining compression method (by r/w tmp file)\n",
    "import tifffile\n",
    "import os\n",
    "\n",
    "\n",
    "def wasteful_compression(img, compression):\n",
    "    try:\n",
    "        os.remove(\"./temp.tiff\")\n",
    "    except OSError:\n",
    "        pass\n",
    "    tifffile.imwrite(\n",
    "        \"./temp.tiff\",\n",
    "        img,\n",
    "        bigtiff=True,\n",
    "        photometric=\"minisblack\",\n",
    "        planarconfig=\"separate\",\n",
    "        tile=(16, 16),\n",
    "        compression=compression,\n",
    "        compressionargs={\"level\": 8},\n",
    "        metadata={\"axes\": \"YX\"},\n",
    "    )\n",
    "    sample_path = Path(\"./temp.tiff\")\n",
    "    reader = AICSImage(sample_path)\n",
    "    img = reader.get_image_data(\"YX\")\n",
    "    return img\n",
    "\n",
    "\n",
    "compression_techniques = [\"JPEGXR\", \"JPEG_2000_LOSSY\", \"LERC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [1/3]: JPEGXR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [02:17,  5.85it/s]\n",
      "194it [00:32,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [2/3]: JPEG_2000_LOSSY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [05:23,  2.49it/s]\n",
      "194it [01:16,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [3/3]: LERC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "806it [01:20, 10.05it/s]\n",
      "194it [00:18, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "### Compression with classic techniques and appending 'original' 'method'\n",
    "import shutil\n",
    "\n",
    "\n",
    "def compress_dir(compression, path, copy_gt=True):\n",
    "    output_path = path / Path(compression)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for image_path in tqdm(path.glob(\"*.tiff\")):\n",
    "        output_image_path = output_path / Path(image_path.name)\n",
    "        if not output_image_path.is_file():\n",
    "            if image_path.name.endswith(\"GT.tiff\") and copy_gt:\n",
    "                shutil.copyfile(image_path, output_image_path)\n",
    "            elif image_path.name.endswith(\"IM.tiff\"):\n",
    "                reader = AICSImage(image_path)\n",
    "                img = reader.get_image_data(\"YX\")\n",
    "                OmeTiffWriter.save(\n",
    "                    wasteful_compression(img, compression),\n",
    "                    output_image_path,\n",
    "                    dim_order=\"YX\",\n",
    "                )\n",
    "\n",
    "\n",
    "def extract_origin_dir(path):\n",
    "    output_path = path / Path(\"original\")\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for image_path in path.glob(\"*IM.tiff\"):\n",
    "        output_image_path = output_path / Path(image_path.name)\n",
    "        if not output_image_path.is_file():\n",
    "            shutil.copyfile(image_path, output_image_path)\n",
    "\n",
    "\n",
    "for i, compression in enumerate(compression_techniques):\n",
    "    print(f\"step [{i+1}/{len(compression_techniques)}]: {compression}\")\n",
    "    compress_dir(compression, train_path_2d, True)\n",
    "    compress_dir(compression, holdout_path_2d, False)\n",
    "\n",
    "extract_origin_dir(holdout_path_2d)\n",
    "compression_techniques.append(\"original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Leanring Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just use the pretrained model provided by the CompressAI team. Requires around 16 hours (1 A100 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compressai.zoo.image import cfgs\n",
    "from compressai.zoo import image_models\n",
    "\n",
    "configurations=[]\n",
    "for model in image_models.keys():\n",
    "    if \"3d\" not in model.lower():  # only consider 2d cases\n",
    "        for metric in ['mse','ms-ssim']:\n",
    "            configurations.append((model,max(cfgs[model]),metric))\n",
    "\n",
    "for setting in configurations:\n",
    "    for image in holdout_path_2d.glob('*IM*.tiff'): \n",
    "        model_name= setting[0]+'_'+setting[2]+'_'+str(setting[1])+'_RGB'\n",
    "        path_encoded= image.parent/model_name/str(image.stem+'_encoded')\n",
    "        path_encoded.parent.mkdir(exist_ok=True)\n",
    "        path_decoded= image.parent/model_name/str(image.stem+'_decoded.tiff')\n",
    "        path_decoded.parent.mkdir(exist_ok=True)\n",
    "        if not path_decoded.is_file():\n",
    "            !python3 ../../../../CompressAI/examples/codec.py encode {image} -o {path_encoded} --model {setting[0]} -q {setting[1]} --channel 3 -m {setting[2]} --cuda\n",
    "            !python3 ../../../../CompressAI/examples/codec.py decode {path_encoded} -o {path_decoded} --channel 3 --cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare both the classic and DL-based methods and write all the metrics to a csv file. The metrics include: Quality (MSE, SSIM, PSNR, Pearson Correlation) and Storage savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_metrics(holdout_path_2d, Path(\"./\") / \"compression_2d_metric.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_compressAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
