{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Exp: Compress 2D\n",
    "- This notebook contains:\n",
    "  -  compression training (from scratch) using `train.py`;\n",
    "  -  compressed model generation using `codec.py`;\n",
    "  -  metric calculation:\n",
    "     -  brightfield image ssim/psnr/corr;\n",
    "     -  fluorescent prediction image ssim/psnr/corr;\n",
    "     -  compression ratio; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import modules:\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import monai\n",
    "import torch\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# define funcs and hyper-parameters:\n",
    "\n",
    "_SEED = 2023\n",
    "np.random.seed(_SEED)\n",
    "random.seed(_SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(_SEED)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def normalizeItensity(image):\n",
    "    # Convert the image data to a floating-point data type\n",
    "    img = image.astype(np.float32)\n",
    "    # Convert the image to a toch Tensor\n",
    "    img = torch.from_numpy(img)\n",
    "    # Normalize the intensity of the image using the MONAI NormalizeIntensity transform\n",
    "    normalize_intensity = monai.transforms.NormalizeIntensity()\n",
    "    img_normalized = normalize_intensity(img)\n",
    "    # Convert the normalized image back to a numpy array\n",
    "    return img_normalized.numpy()\n",
    "\n",
    "\n",
    "def transform_img(image):\n",
    "    img = image.astype(np.float32) / 65535\n",
    "    return img\n",
    "\n",
    "\n",
    "def compare_images(path1, path2, gt=True):\n",
    "    # Load the two images\n",
    "    image1 = AICSImage(path1).get_image_data(\"YX\")\n",
    "    image2 = AICSImage(path2).get_image_data(\"YX\")\n",
    "    if gt:\n",
    "        # image1 = image1.astype(np.float32)\n",
    "        # # Scale the values in image1 to the range [0, 65535]\n",
    "        # scaled_image = (image1 / np.max(image1) * 65535).round().astype(np.uint16)\n",
    "        # image1 = scaled_image\n",
    "        image1 = transform_img(image1)\n",
    "        image2 = transform_img(image2)\n",
    "    # Calculate metrics\n",
    "    mse = np.sum((image1 - image2) ** 2) / (924 * 624)\n",
    "    ssim_value = ssim(image1, image2, data_range=1)\n",
    "    psnr_value = psnr(image1, image2, data_range=1)\n",
    "    corr = np.corrcoef(image1.ravel(), image2.ravel())[0, 1]\n",
    "    # psnr = 10 * np.log10(1 / (mse + 0.000001))\n",
    "    return mse, ssim_value, psnr_value, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# firstly, use fine_tune_v12 to generate compressed images, and calculate metrics:\n",
    "test_data_path = sorted(\n",
    "    Path(\n",
    "        \"/mnt/data/ISAS.DE/yu.zhou/Yu/project/data_compression/data/labelfree_2d/v2/test\"\n",
    "    ).glob(\"*.tiff\")\n",
    ")\n",
    "random.seed(_SEED)\n",
    "test_data_path = random.sample(test_data_path, 50)\n",
    "compress_data_path = Path.cwd()\n",
    "metrics = [\"ms-ssim\"]\n",
    "models = [\"bmshj2018-factorized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_path = Path(\n",
    "    \"/mnt/eternus/users/Yu/project/data_compression/experiment/paper_exp/2d/compression/raw_img\"\n",
    ")\n",
    "for tmp_path in test_data_path:\n",
    "    shutil.copy(tmp_path, copy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for image in test_data_path: \n",
    "            model_name= model+'_'+metric+'_'+'8_v12'\n",
    "            path_encoded= compress_data_path/model_name/str(image.stem+'_encoded')\n",
    "            path_encoded.parent.mkdir(exist_ok=True, parents = True)\n",
    "            path_decoded= compress_data_path/model_name/str(image.stem+'_decoded.tiff')\n",
    "            path_decoded.parent.mkdir(exist_ok=True, parents = True)\n",
    "            if not path_decoded.is_file():\n",
    "                !python3 ../../../codec.py encode {image} -o {path_encoded} --model {model} -q 8 -m {metric} --cuda --checkpoint {path_encoded.parent / \"model.pth.tar\"}\n",
    "                # !python3 ../codec.py encode {image} -o {path_encoded} --model bmshj2018-factorized -q 8 -m {metric} --cuda\n",
    "                !python3 ../../../codec.py decode {path_encoded} -o {path_decoded} --model {model} -q 8 -m {metric} --cuda --checkpoint {path_encoded.parent / \"model.pth.tar\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. brightfield image metric: mse/ssim/psnr/corr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00022894785484657378 SSIM: 0.9769605329180757 PSNR: 38.54215274176078 CORR: 0.9203892596547221\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        model_name = model + \"_\" + metric + \"_\" + \"8_v12\"\n",
    "        decoded_paths = sorted((compress_data_path / model_name).glob(\"*.tiff\"))\n",
    "        mse_value = AverageMeter()\n",
    "        ssim_value = AverageMeter()\n",
    "        psnr_value = AverageMeter()\n",
    "        corr_value = AverageMeter()\n",
    "        for i, (decode_path, raw_path) in enumerate(\n",
    "            zip(decoded_paths, sorted(test_data_path))\n",
    "        ):\n",
    "            tmp_mse, tmp_ssim, tmp_psnr, tmp_corr = compare_images(\n",
    "                decode_path, raw_path\n",
    "            )\n",
    "            mse_value.update(tmp_mse)\n",
    "            ssim_value.update(tmp_ssim)\n",
    "            psnr_value.update(tmp_psnr)\n",
    "            corr_value.update(tmp_corr)\n",
    "        print(\n",
    "            \"MSE:\",\n",
    "            mse_value.avg,\n",
    "            \"SSIM:\",\n",
    "            ssim_value.avg,\n",
    "            \"PSNR:\",\n",
    "            psnr_value.avg,\n",
    "            \"CORR:\",\n",
    "            corr_value.avg,\n",
    "        )\n",
    "        # Define the filename\n",
    "        filename = Path.cwd() / model_name / \"note.txt\"\n",
    "        # Open the file for writing (creating if it doesn't exist)\n",
    "        with open(filename, \"a\") as file:\n",
    "            # Write the values to the file\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            file.write(f\"[Timestamp]: {timestamp}\\n\")\n",
    "            file.write(f\"MSE: {mse_value.avg}\\n\")\n",
    "            file.write(f\"SSIM: {ssim_value.avg}\\n\")\n",
    "            file.write(f\"PSNR: {psnr_value.avg}\\n\")\n",
    "            file.write(f\"Correlation: {corr_value.avg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_compressAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
